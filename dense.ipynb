{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import keras.layers as l\n",
    "from keras.models import load_model\n",
    "import dataset_tools as dt\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = '/mnt/data/deepfake/datasets/faces/Actor_01/'\n",
    "dataset_2 = '/mnt/data/deepfake/datasets/faces/Actor_02/'\n",
    "\n",
    "pics_a = dt.get_pics(dataset_1)\n",
    "pics_b = dt.get_pics(dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_net:\n",
    "    def __init__(self,pics_a, pics_b, ratio = 0.9):\n",
    "        self.DIM = 100 #image dimension\n",
    "        Xa, Xb = dt.format_images(pics_a, pics_b, self.DIM, self.DIM)\n",
    "        self.train_a, self.test_a = dt.separate_dataset(Xa, ratio)\n",
    "        self.train_b, self.test_b = dt.separate_dataset(Xb, ratio)\n",
    "                \n",
    "    def train(self, n_epochs = 1, verbose=0) :\n",
    "        for n in range(n_epochs):\n",
    "            print(\"Epoch %d / %d\" % ((n+1),n_epochs), end='\\r')\n",
    "            self.ae_a.fit(self.train_a, self.train_a, epochs=1, verbose=verbose)\n",
    "            self.ae_b.fit(self.train_b, self.train_b, epochs=1, verbose=verbose)\n",
    "            \n",
    "    def save(self, folder) :\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        self.ae_a.save(folder + \"/ae_a.h5\")\n",
    "        self.ae_b.save(folder + \"/ae_b.h5\")\n",
    "        \n",
    "    def load(self, folder) :\n",
    "        self.ae_a = load_model(folder + \"/ae_a.h5\")\n",
    "        self.ae_b = load_model(folder + \"/ae_b.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_simple(df_net):\n",
    "    def __init__(self,pics_a, pics_b, ratio = 0.9):\n",
    "        df_net.__init__(self, pics_a, pics_b, ratio)\n",
    "        self.create_network()\n",
    "        \n",
    "    def create_network(self) :\n",
    "        DIM = self.DIM\n",
    "        input_layer = l.Input(shape = (DIM * DIM,))\n",
    "        encoded = l.Dense(32, activation='relu')(input_layer)\n",
    "        decoded_a = l.Dense(DIM*DIM, activation = \"sigmoid\")(encoded)\n",
    "        decoded_b = l.Dense(DIM*DIM, activation = \"sigmoid\")(encoded)\n",
    "        self.ae_a = k.Model(input_layer, decoded_a)\n",
    "        self.ae_b = k.Model(input_layer, decoded_b)\n",
    "        encodeur = k.Model(input_layer, encoded)\n",
    "        \n",
    "        self.ae_a.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        self.ae_b.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_simple(df_net):\n",
    "    def __init__(self,pics_a, pics_b, ratio = 0.9):\n",
    "        df_net.__init__(self, pics_a, pics_b, ratio)\n",
    "        \n",
    "        self.train_a = self.train_a.reshape((len(self.train_a), 100,100,1))\n",
    "        self.train_b = self.train_b.reshape((len(self.train_b), 100,100,1))\n",
    "        self.test_a = self.test_a.reshape((len(test_xa), 100,100,1))\n",
    "        test_xb = test_xb.reshape((len(test_xb), 100,100,1))\n",
    "        self.create_network()\n",
    "        \n",
    "    def create_network(self) :\n",
    "        input_img = l.Input(shape=(self.DIM, self.DIM, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = l.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = l.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = l.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = l.MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = l.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = l.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        # at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "        xa = l.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        xa = l.UpSampling2D((2, 2))(xa)\n",
    "        xa = l.Conv2D(8, (3, 3), activation='relu', padding='same')(xa)\n",
    "        xa = l.UpSampling2D((2, 2))(xa)\n",
    "        xa = l.Conv2D(16, (3, 3), activation='relu')(xa)\n",
    "        xa = l.UpSampling2D((2, 2))(xa)\n",
    "        decoded_a = l.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(xa)\n",
    "\n",
    "        xb = l.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        xb = l.UpSampling2D((2, 2))(xb)\n",
    "        xb = l.Conv2D(8, (3, 3), activation='relu', padding='same')(xb)\n",
    "        xb = l.UpSampling2D((2, 2))(xb)\n",
    "        xb = l.Conv2D(16, (3, 3), activation='relu')(xb)\n",
    "        xb = l.UpSampling2D((2, 2))(xb)\n",
    "        decoded_b = l.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(xb)\n",
    "\n",
    "        self.ae_a = k.Model(input_img, decoded_a)\n",
    "        self.ae_b = k.Model(input_img, decoded_b)\n",
    "\n",
    "        encoder = k.Model(input_img, encoded)\n",
    "\n",
    "        self.ae_a.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        self.ae_b.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1 / 5\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_58 to have 4 dimensions, but got array with shape (900, 10000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-9fc6067314a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestDense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpics_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpics_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtestDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestDense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-193-524f99135a18>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d / %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mae_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_58 to have 4 dimensions, but got array with shape (900, 10000)"
     ]
    }
   ],
   "source": [
    "testDense = cnn_simple(pics_a, pics_b)\n",
    "\n",
    "testDense.train(5)\n",
    "\n",
    "test_img = testDense.test_a[10]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_img.reshape(100,100), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "pred = testDense.ae_a.predict(np.array([test_img]))\n",
    "plt.imshow(pred[0].reshape(100,100), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDense = dense_simple(pics_a, pics_b)\n",
    "testDense.save('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
